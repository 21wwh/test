{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888abbd7",
   "metadata": {},
   "source": [
    "# 作业与作业提示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5030396e",
   "metadata": {},
   "source": [
    "![](WechatIMG55.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b7c5d",
   "metadata": {},
   "source": [
    "![](计算图.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e1442",
   "metadata": {},
   "source": [
    "作业内容：\n",
    "1. 绘制ppt作业中二元函数类似于上图的计算图；\n",
    "2. 使用torch算出计算图中所有节点分别对x1, x2的导数（类似于下图，但是下图仅给出了所有圆圈节点对x1的导数）；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792aa3f",
   "metadata": {},
   "source": [
    "![](ppt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fe1363",
   "metadata": {},
   "source": [
    "$$ \n",
    "y = f(x_1,x_2)=ln(x_1)+x_1x_2-sin(x_2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cbd719",
   "metadata": {},
   "source": [
    "\\begin{aligned} \n",
    "&\\text{复合函数表示如下：} \\\\\n",
    "&v_{-1} = x_1 \\\\\n",
    "&v_0 = x_2 \\\\\n",
    "&v_1 = ln(v_{-1}) \\\\\n",
    "&v_2 = v_{-1}v_0 \\\\\n",
    "&v_3 = sin(v_0) \\\\\n",
    "&v_4 = v_1+v_2 \\\\\n",
    "&v_5 = v_4-v_3\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43c7d857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def sin(x):\n",
    "    return torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "989ed748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "x2 = torch.tensor(5.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ee3a984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v_minus_1 = x1\n",
    "v0 = x2\n",
    "v1 = torch.log(v_minus_1)\n",
    "v2 = v_minus_1*v0\n",
    "v3 = sin(v0)\n",
    "v4 = v1 + v2\n",
    "v5 = v4 - v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93072a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T06:51:20.388156Z",
     "iopub.status.busy": "2024-11-19T06:51:20.387498Z",
     "iopub.status.idle": "2024-11-19T06:51:20.397574Z",
     "shell.execute_reply": "2024-11-19T06:51:20.395587Z",
     "shell.execute_reply.started": "2024-11-19T06:51:20.388109Z"
    }
   },
   "source": [
    "$$\n",
    "\\frac{dv1}{dx1}=\\frac{1}{v_{-1}}\\frac{dv_{-1}}{dx_1}\\\\\n",
    "\\frac{dv_3}{dx_1}=cosv_0\\frac{dv_0}{dx_1}=cosv_0*0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61d2c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dict = {\"v_minus_1\": v_minus_1, \"v0\": v0, \"v1\": v1, \"v2\": v2, \"v3\": v3, \"v4\": v4, \"v5\": v5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "835545bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = {\"x1\": x1, \"x2\": x2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1067564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_minus_1对x1的导数： tensor(1.)\n",
      "v_minus_1对x2的导数： tensor(0.)\n",
      "v0对x1的导数： tensor(0.)\n",
      "v0对x2的导数： tensor(1.)\n",
      "v1对x1的导数： tensor(0.5000)\n",
      "v1对x2的导数： tensor(0.)\n",
      "v2对x1的导数： tensor(5.)\n",
      "v2对x2的导数： tensor(2.)\n",
      "v3对x1的导数： tensor(0.)\n",
      "v3对x2的导数： tensor(0.2837)\n",
      "v4对x1的导数： tensor(5.5000)\n",
      "v4对x2的导数： tensor(2.)\n",
      "v5对x1的导数： tensor(5.5000)\n",
      "v5对x2的导数： tensor(1.7163)\n"
     ]
    }
   ],
   "source": [
    "for node_name in node_dict:\n",
    "    for var_name in var_dict:\n",
    "        if x1.grad is not None:\n",
    "            x1.grad.zero_()\n",
    "        else:\n",
    "            x1.grad = torch.tensor(0.0)\n",
    "        if x2.grad is not None:\n",
    "            x2.grad.zero_()\n",
    "        else:\n",
    "            x2.grad = torch.tensor(0.0)\n",
    "\n",
    "        node_dict[node_name].backward(retain_graph=True)\n",
    "        print(f\"{node_name}对{var_name}的导数：\", var_dict[var_name].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49e7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3232e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d3ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(0.0, requires_grad=True)\n",
    "x2 = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73f64981",
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = x1\n",
    "v1 = x2\n",
    "v2 = v0**2\n",
    "v3 = 2*v1\n",
    "v4 = v2+v3+1\n",
    "v5 = func(v4)\n",
    "v6 = func(3*v5)\n",
    "v7 = func(v4+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c34da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dict = {\"v0\": v0, \"v1\": v1, \"v2\": v2, \"v3\": v3, \"v4\": v4, \"v5\": v5,\"v6\":v6,\"v7\":v7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fbe0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = {\"x1\": x1, \"x2\": x2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbbdc074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0对x1的导数： tensor(1.)\n",
      "v0对x2的导数： tensor(0.)\n",
      "v1对x1的导数： tensor(0.)\n",
      "v1对x2的导数： tensor(1.)\n",
      "v2对x1的导数： tensor(0.)\n",
      "v2对x2的导数： tensor(0.)\n",
      "v3对x1的导数： tensor(0.)\n",
      "v3对x2的导数： tensor(2.)\n",
      "v4对x1的导数： tensor(0.)\n",
      "v4对x2的导数： tensor(2.)\n",
      "v5对x1的导数： tensor(0.)\n",
      "v5对x2的导数： tensor(0.0904)\n",
      "v6对x1的导数： tensor(0.)\n",
      "v6对x2的导数： tensor(0.0139)\n",
      "v7对x1的导数： tensor(0.)\n",
      "v7对x2的导数： tensor(0.0353)\n"
     ]
    }
   ],
   "source": [
    "for node_name in node_dict:\n",
    "    for var_name in var_dict:\n",
    "        if var_dict[var_name].grad is not None:\n",
    "            var_dict[var_name].grad.zero_()\n",
    "        else:\n",
    "            var_dict[var_name].grad = torch.tensor(0.0)\n",
    "\n",
    "        node_dict[node_name].backward(retain_graph=True)\n",
    "        print(f\"{node_name}对{var_name}的导数：\", var_dict[var_name].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4d7bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d3870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成x值，范围从-10到10，共100个点\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "# 计算sigmoid函数值\n",
    "y = 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 绘制sigmoid函数图像\n",
    "plt.plot(x, y)\n",
    "plt.title('Sigmoid Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('sigmoid(x)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
